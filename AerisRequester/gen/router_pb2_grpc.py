# Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
import grpc

from google.protobuf import empty_pb2 as google_dot_protobuf_dot_empty__pb2
import notification_pb2 as notification__pb2
import router_pb2 as router__pb2


class RouterV1Stub(object):
  # missing associated documentation comment in .proto file
  pass

  def __init__(self, channel):
    """Constructor.

    Args:
      channel: A grpc.Channel.
    """
    self.Publish = channel.unary_unary(
        '/RouterV1/Publish',
        request_serializer=router__pb2.PublishRequest.SerializeToString,
        response_deserializer=google_dot_protobuf_dot_empty__pb2.Empty.FromString,
        )
    self.Subscribe = channel.unary_stream(
        '/RouterV1/Subscribe',
        request_serializer=router__pb2.SubscribeRequest.SerializeToString,
        response_deserializer=notification__pb2.NotificationBatch.FromString,
        )
    self.Get = channel.unary_stream(
        '/RouterV1/Get',
        request_serializer=router__pb2.GetRequest.SerializeToString,
        response_deserializer=notification__pb2.NotificationBatch.FromString,
        )
    self.GetDatasets = channel.unary_stream(
        '/RouterV1/GetDatasets',
        request_serializer=router__pb2.DatasetsRequest.SerializeToString,
        response_deserializer=router__pb2.DatasetsResponse.FromString,
        )
    self.CreateDataset = channel.unary_unary(
        '/RouterV1/CreateDataset',
        request_serializer=router__pb2.CreateDatasetRequest.SerializeToString,
        response_deserializer=google_dot_protobuf_dot_empty__pb2.Empty.FromString,
        )


class RouterV1Servicer(object):
  # missing associated documentation comment in .proto file
  pass

  def Publish(self, request, context):
    """Publish is used to send notifications to aeris.
    They will be saved into the storage and sent to all
    the clients subscribing to the same device/path.

    * Publish guarantees atomicity of the data saved per {timestamp+path+key}.
    For Notification => For one Notification having multiple keys,
    each key is ensured to be saved atomically
    but atomicity is not guaranteed for the entire notification.
    For NotificationBatch =>  if Notif[1] and Notif[5]
    both have updates for a {timestamp+path+key}
    either the update of Notif[1] will be saved, or the update of Notif[5] will be saved.
    The value will be one or the other, not a corrupted combination of both requests.

    * There is no guarantee for write order within a single publish request.
    When sending multiple notifications where multiple notification will have
    the same timestamp, path and keys,
    Publish does not guarantee that Notif[1] will be processed before Notif[5]
    This means that for two notifications in the same Publish call having the
    same {timestamp+path+key}, the result is undefined and will randomly vary
    (i.e. the first notif data will be saved, or the second one).
    The client must send two synchronous Publish requests to guarantee
    the write order at which the requests are processed.

    * Publish is asynchronous by default:
    When the call to Publish ends without error, it means the data has been
    correctly received by aeris but not stored yet.
    So, if a "get" call is done right after the Publish call, the get might
    not return the data just published.
    When the "sync" field is set to true in PublishRequest, the Publish
    will be synchronous:
    When the call to Publish ends without error, it means the data has been
    correctly received AND stored by aeris.
    So, if a "get" call is done right after the synchronous Publish call, the get will
    return the data just published (unless someone else stored more recent data of course).

    * Client-side and Server-side timestamping:
    The notification object has a timestamp that can be populated by the client.
    In case the Client sends a notification with a "null" timestamp as the
    Notification.timestamp field, the server will populate the timestamp with
    the current time of the node with the server process is running.
    This "current time" will be queried once at the beginning of the Publish request
    and will be used as the Notification.timestamp for all the notification having this field
    as null.
    """
    context.set_code(grpc.StatusCode.UNIMPLEMENTED)
    context.set_details('Method not implemented!')
    raise NotImplementedError('Method not implemented!')

  def Subscribe(self, request, context):
    """Subscribe allows the client to request a live stream of updates
    (V1: either based on regexp or exact match, V2: based on exact match)

    There is no order guarantee for batches received by subscribers.
    It means that two batches A and B published synchronously (B is published after A)
    the subscribers can receive batch A first or B second, OR batch B first and A second.
    This sis also true for notifications within a batch.
    The backend can decide to split a batch and reorder notifications so subscribers
    might receive notifications within a batch in a different order that they were published.
    """
    context.set_code(grpc.StatusCode.UNIMPLEMENTED)
    context.set_details('Method not implemented!')
    raise NotImplementedError('Method not implemented!')

  def Get(self, request, context):
    # missing associated documentation comment in .proto file
    pass
    context.set_code(grpc.StatusCode.UNIMPLEMENTED)
    context.set_details('Method not implemented!')
    raise NotImplementedError('Method not implemented!')

  def GetDatasets(self, request, context):
    # missing associated documentation comment in .proto file
    pass
    context.set_code(grpc.StatusCode.UNIMPLEMENTED)
    context.set_details('Method not implemented!')
    raise NotImplementedError('Method not implemented!')

  def CreateDataset(self, request, context):
    """CreateDataset from a given Dataset wrapped in a CreateDatasetRequest
    """
    context.set_code(grpc.StatusCode.UNIMPLEMENTED)
    context.set_details('Method not implemented!')
    raise NotImplementedError('Method not implemented!')


def add_RouterV1Servicer_to_server(servicer, server):
  rpc_method_handlers = {
      'Publish': grpc.unary_unary_rpc_method_handler(
          servicer.Publish,
          request_deserializer=router__pb2.PublishRequest.FromString,
          response_serializer=google_dot_protobuf_dot_empty__pb2.Empty.SerializeToString,
      ),
      'Subscribe': grpc.unary_stream_rpc_method_handler(
          servicer.Subscribe,
          request_deserializer=router__pb2.SubscribeRequest.FromString,
          response_serializer=notification__pb2.NotificationBatch.SerializeToString,
      ),
      'Get': grpc.unary_stream_rpc_method_handler(
          servicer.Get,
          request_deserializer=router__pb2.GetRequest.FromString,
          response_serializer=notification__pb2.NotificationBatch.SerializeToString,
      ),
      'GetDatasets': grpc.unary_stream_rpc_method_handler(
          servicer.GetDatasets,
          request_deserializer=router__pb2.DatasetsRequest.FromString,
          response_serializer=router__pb2.DatasetsResponse.SerializeToString,
      ),
      'CreateDataset': grpc.unary_unary_rpc_method_handler(
          servicer.CreateDataset,
          request_deserializer=router__pb2.CreateDatasetRequest.FromString,
          response_serializer=google_dot_protobuf_dot_empty__pb2.Empty.SerializeToString,
      ),
  }
  generic_handler = grpc.method_handlers_generic_handler(
      'RouterV1', rpc_method_handlers)
  server.add_generic_rpc_handlers((generic_handler,))


class AlphaStub(object):
  """Alpha services are services which are not supported and
  can be added/removed/changed anytime, without notice.
  Clients should not user them and build applications on top of this service
  """

  def __init__(self, channel):
    """Constructor.

    Args:
      channel: A grpc.Channel.
    """
    self.Search = channel.unary_stream(
        '/Alpha/Search',
        request_serializer=router__pb2.SearchRequest.SerializeToString,
        response_deserializer=notification__pb2.NotificationBatch.FromString,
        )
    self.SearchSubscribe = channel.unary_stream(
        '/Alpha/SearchSubscribe',
        request_serializer=router__pb2.SearchRequest.SerializeToString,
        response_deserializer=notification__pb2.NotificationBatch.FromString,
        )


class AlphaServicer(object):
  """Alpha services are services which are not supported and
  can be added/removed/changed anytime, without notice.
  Clients should not user them and build applications on top of this service
  """

  def Search(self, request, context):
    """you know, for search...
    """
    context.set_code(grpc.StatusCode.UNIMPLEMENTED)
    context.set_details('Method not implemented!')
    raise NotImplementedError('Method not implemented!')

  def SearchSubscribe(self, request, context):
    """SearchSubscribe allows the client to request a live stream of updates
    based on client search request
    """
    context.set_code(grpc.StatusCode.UNIMPLEMENTED)
    context.set_details('Method not implemented!')
    raise NotImplementedError('Method not implemented!')


def add_AlphaServicer_to_server(servicer, server):
  rpc_method_handlers = {
      'Search': grpc.unary_stream_rpc_method_handler(
          servicer.Search,
          request_deserializer=router__pb2.SearchRequest.FromString,
          response_serializer=notification__pb2.NotificationBatch.SerializeToString,
      ),
      'SearchSubscribe': grpc.unary_stream_rpc_method_handler(
          servicer.SearchSubscribe,
          request_deserializer=router__pb2.SearchRequest.FromString,
          response_serializer=notification__pb2.NotificationBatch.SerializeToString,
      ),
  }
  generic_handler = grpc.method_handlers_generic_handler(
      'Alpha', rpc_method_handlers)
  server.add_generic_rpc_handlers((generic_handler,))
